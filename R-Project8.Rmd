---
title: "Q2-R-Project-Group-8, TFIDF"
author: "Henry Fong, Ian Zhang, Adam Walters"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning  = FALSE}
library(rio)
library(readxl)
library(openxlsx)
library(tm)
library(wordcloud)
library(SnowballC)
library(RColorBrewer)
library(tidyverse)
library(MASS)

```

```{r}
df <- read_csv("ChatGPT_ResponsesOnAI.csv")

```

# TF-IDF !!!

```{r}
corpG <- Corpus(VectorSource(df$Response))

```

```{r}
# Function to remove unknown characters
remove_unknown_characters <- function(text) {
  encoding <- "UTF-8"
  clean_text <- iconv(text, to = encoding, sub = "")
  return(clean_text)
}

# Apply the function to each document in the corpus
corpG <- tm_map(corpG, content_transformer(remove_unknown_characters))
```

```{r, warning = FALSE}
corpG <- tm_map(corpG,content_transformer(tolower))
corpG <- tm_map(corpG,removeNumbers)
corpG <- tm_map(corpG,removeWords,stopwords("english"))
corpG <- tm_map(corpG,removePunctuation)
corpG <- tm_map(corpG, stripWhitespace)
```

```{r, warning = FALSE}
corpG <- tm_map(corpG,removeWords, c("Ai", "AI", "ai"))
corpG <- tm_map(corpG,stemDocument)

```

```{r}
tdG <- TermDocumentMatrix(corpG)
tdGM <- as.matrix(tdG)
```

```{r}
termG <- rowSums(tdGM)
termG <- sort(termG, decreasing = TRUE)
termG2 <- data.frame(word = names(termG),freq = termG)

```

```{r}
plot(termG2$freq,xlab = "word index", ylab = "Frequency")
```

```{r}
wordcloud(termG2$word,termG2$freq,scale = c(2,0.5))
```

```{r}
numTermsGte2 <- sum(termG2$freq > 1)
cols <- rainbow(numTermsGte2)
plot(termG2$freq[termG2$freq > 1], xlab = "Word index", ylab = "Frequency")

wordcloud(termG2$word[termG2$freq >1], termG2$freq[termG2$freq > 1],scale = c(2,0.5), min.freq = 2, rot.per = .5,colors = cols, random.color = FALSE, ordered.colors = TRUE)
```

```{r}

tdGM[1:4,1:6]
tfidf <- TermDocumentMatrix(corpG, control = list(weighting = function(x) {weightTfIdf(x)}))
tfidf <- as.matrix(tfidf)
tfidf[1:4,1:6]
```

```{r}
# plot tf values vs tfidf values
tfV <- as.vector(tdGM)
tfidfV <- as.vector(tfidf)
plot(tfV,tfidfV,xlab = "TF", ylab = "TF-IDF")
```

```{r, warning = FALSE}
# word cloud on tfidf values
tfidfByWords <-rowSums(tfidf)
wordcloud(rownames(tfidf),tfidfByWords,scale = c(2,0.5))
```

```{r}
summary(tfidfByWords)
```

```{r, warning = FALSE}
# word cloud based on TFIDF values, min freq
wordcloud(rownames(tfidf),tfidfByWords,scale = c(2,0.5), min.freq = 0.75)
```

```{r}
# orders words by TFIDF values
orderWords <- order(tfidfByWords, decreasing = TRUE)
tfidfOrder <- tfidf[orderWords,]
rownames(tfidfOrder)[1:10]


```

```{r}
# Create a boxplot of the top 10 TFIDF values
tfidfTr <- t(tfidfOrder)
boxplot(tfidfTr[,1:10],cex = 0.5)
```

```{r}
dim(tfidfTr)
# dimensions of the transposed matrix
```

```{r}
studCodes = df$Number
distdat <- dist(tfidfTr)
# multidimensional scaling and scatter plot
fit <- cmdscale(distdat, k = 2)
plot(fit, pch = 16, xlab = "Coordinate 1 ", ylab = "Coordinate 2")
text(fit +0.02, label = studCodes, cex = 0.7)

```

```{r}
# Parallel coordinates plot
cols <- rainbow(dim(tfidfTr)[[1]])
parcoord(tfidfTr[,1:10],col = cols)
```

# Sentiment Analysis !!!

```{r}


# Function to remove unknown characters
remove_unknown_characters <- function(text) {
  encoding <- "UTF-8"
  clean_text <- iconv(text, to = encoding, sub = "")
  return(clean_text)
}

# Apply the function to each document in the corpus
# Function to remove unknown characters
remove_unknown_characters <- function(text) {
  encoding <- "UTF-8"
  clean_text <- iconv(text, to = encoding, sub = "")
  return(clean_text)
}

# Apply the function to each element in the df$Response column
df$Response <- sapply(df$Response, remove_unknown_characters)

# Further text preprocessing on df$Response
df$Response <- tolower(df$Response)
df$Response <- gsub("[0-9]", "", df$Response)  # remove numbers
df$Response <- removeWords(df$Response, stopwords("english"))
df$Response <- removePunctuation(df$Response)
df$Response <- stripWhitespace(df$Response)
df$Response <- removeWords(df$Response, c("ai"))
df$Response <- stemDocument(df$Response)


```



```{r}
# Sentiment analysis
p2 <- polarity(df$Response, group = df$Number,
               polarity.frame = key.pol, negators = negation.words,
               amplifiers = amplification.words,
               deamplifiers = deamplification.words,
               n.before = 2, n.after = 2)


# Handle NaN values
p2$all$polarity[is.nan(p2$all$polarity)] <- 0
```

```{r}
print(p2$all$polarity)

```

```{r}
# Create a matrix for pairwise comparisons
polarity_matrix <- matrix(NA, nrow = nrow(df), ncol = nrow(df))

# Fill the matrix with pairwise sentiment scores
for (i in 1:nrow(df)) {
  for (j in 1:nrow(df)) {
    # Skip self-comparison
    if (i != j) {
      polarity_matrix[i, j] <- p2$all$polarity[i] - p2$all$polarity[j]
    }
  }
}

# Convert the matrix to a data frame for easier analysis
polarity_df <- as.data.frame(polarity_matrix)
colnames(polarity_df) <- paste("Doc", 1:nrow(df), sep = "")

# Display the polarity matrix
print("Polarity Matrix:")
print(polarity_df)

```




```{r}
# Assuming you have already calculated polarity scores using the polarity function
# ...

# Extract relevant information for plotting
doc_numbers <- df$Number
polarity_values <- p2$all$polarity

# Create a data frame for plotting
polarity_df <- data.frame(Document = doc_numbers, Polarity = polarity_values)

# Plotting the bar plot
library(ggplot2)

ggplot(polarity_df, aes(x = factor(Document), y = Polarity, fill = factor(Document))) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  labs(title = "Sentiment Scores by Document",
       x = "Document Number",
       y = "Sentiment Score") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r, warning = FALSE}

# Separate positive and negative documents based on polarity
positive_docs <- df$Response[p2$all$polarity > 0]
negative_docs <- df$Response[p2$all$polarity < 0]

# Calculate word frequencies for positive and negative documents
positive_freq <- table(unlist(strsplit(positive_docs, " ")))
negative_freq <- table(unlist(strsplit(negative_docs, " ")))

# Ensure both frequencies have the same set of words
all_words <- union(names(positive_freq), names(negative_freq))

# Fill in missing words with 0 frequency
positive_freq[setdiff(all_words, names(positive_freq))] <- 0
negative_freq[setdiff(all_words, names(negative_freq))] <- 0

# Combine frequencies, giving more weight to words that are more polarizing
combined_freq <- positive_freq - negative_freq

# Create a word cloud using combined frequencies
wordcloud(words = names(combined_freq), freq = combined_freq,
          scale = c(3, 0.5), min.freq = 1, colors = brewer.pal(8, "RdBu"))

```